{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d234a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kirilltiufanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dee0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"data/all_data_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed03141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time                                                      2021-01-02\n",
       "time.1                                                             6\n",
       "tweetl_t           @StickmanSham @RANK10YGO &gt;Crack a Silly â€œHm...\n",
       "mentions_t                                                    [][][]\n",
       "replies_count_t                                                 20.0\n",
       "                                         ...                        \n",
       "open                                                        0.006985\n",
       "high                                                        0.007366\n",
       "low                                                         0.006975\n",
       "tv                                                                 1\n",
       "Volume                                                    41947109.0\n",
       "Name: 5, Length: 417, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "068d7b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1219\n",
       " 1    1217\n",
       " 0     362\n",
       "Name: tv, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"tv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22da198",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_num = all_data.drop([\"tweetl_t\", \"tweetl_l\", \"mentions_t\", \"mentions_l\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdee9934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>time.1</th>\n",
       "      <th>replies_count_t</th>\n",
       "      <th>retweets_count_t</th>\n",
       "      <th>top_tw_t</th>\n",
       "      <th>likes_count_t</th>\n",
       "      <th>dogecoin_t</th>\n",
       "      <th>dogearmy_t</th>\n",
       "      <th>elonmusk_t</th>\n",
       "      <th>buy_t</th>\n",
       "      <th>...</th>\n",
       "      <th>ladybug_l</th>\n",
       "      <th>already_l</th>\n",
       "      <th>gt_l</th>\n",
       "      <th>subj_l</th>\n",
       "      <th>polar_l</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>tv</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248972</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.007172</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>-1</td>\n",
       "      <td>29383228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.262869</td>\n",
       "      <td>0.106507</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0</td>\n",
       "      <td>41415520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.136352</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>1</td>\n",
       "      <td>31058927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>268.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279962</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.007055</td>\n",
       "      <td>1</td>\n",
       "      <td>31100758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>5</td>\n",
       "      <td>35.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.314670</td>\n",
       "      <td>0.147348</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>-1</td>\n",
       "      <td>57350444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>19</td>\n",
       "      <td>78.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2989.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329047</td>\n",
       "      <td>0.127826</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.310220</td>\n",
       "      <td>1</td>\n",
       "      <td>19257761.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>20</td>\n",
       "      <td>499.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1751.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.306651</td>\n",
       "      <td>0.138017</td>\n",
       "      <td>0.317420</td>\n",
       "      <td>0.322030</td>\n",
       "      <td>0.314180</td>\n",
       "      <td>1</td>\n",
       "      <td>22698952.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>21</td>\n",
       "      <td>57.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351950</td>\n",
       "      <td>0.142881</td>\n",
       "      <td>0.318320</td>\n",
       "      <td>0.325380</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>1</td>\n",
       "      <td>22205970.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>22</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315244</td>\n",
       "      <td>0.118175</td>\n",
       "      <td>0.322610</td>\n",
       "      <td>0.322640</td>\n",
       "      <td>0.312610</td>\n",
       "      <td>-1</td>\n",
       "      <td>23157805.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>23</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>4502.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26748.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.243664</td>\n",
       "      <td>0.091839</td>\n",
       "      <td>0.314450</td>\n",
       "      <td>0.317830</td>\n",
       "      <td>0.312520</td>\n",
       "      <td>0</td>\n",
       "      <td>15291654.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2798 rows Ã— 413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  time.1  replies_count_t  retweets_count_t  top_tw_t  \\\n",
       "0     2021-01-02       1             61.0             173.0       2.0   \n",
       "1     2021-01-02       2             26.0              23.0       2.0   \n",
       "2     2021-01-02       3             22.0             160.0       2.0   \n",
       "3     2021-01-02       4            268.0             555.0       5.0   \n",
       "4     2021-01-02       5             35.0             252.0       2.0   \n",
       "...          ...     ...              ...               ...       ...   \n",
       "2793  2021-04-28      19             78.0             431.0       7.0   \n",
       "2794  2021-04-28      20            499.0             766.0       5.0   \n",
       "2795  2021-04-28      21             57.0             316.0       3.0   \n",
       "2796  2021-04-28      22           1174.0            2506.0       5.0   \n",
       "2797  2021-04-28      23           1471.0            4502.0      40.0   \n",
       "\n",
       "      likes_count_t  dogecoin_t  dogearmy_t  elonmusk_t  buy_t  ...  \\\n",
       "0            1631.0         0.0         0.0         0.0    0.0  ...   \n",
       "1             271.0         0.0         0.0         0.0    0.0  ...   \n",
       "2             866.0         1.0         0.0         0.0    0.0  ...   \n",
       "3            1868.0         1.0         0.0         0.0    4.0  ...   \n",
       "4            1762.0         1.0         0.0         0.0    0.0  ...   \n",
       "...             ...         ...         ...         ...    ...  ...   \n",
       "2793         2989.0         3.0         1.0         1.0    0.0  ...   \n",
       "2794         1751.0         1.0         0.0         0.0    0.0  ...   \n",
       "2795          871.0         0.0         0.0         0.0    0.0  ...   \n",
       "2796        11779.0         1.0         0.0         0.0    2.0  ...   \n",
       "2797        26748.0         4.0         3.0        19.0    3.0  ...   \n",
       "\n",
       "      ladybug_l  already_l  gt_l    subj_l   polar_l      open      high  \\\n",
       "0             0          0     1  0.248972  0.035800  0.006921  0.007172   \n",
       "1             0          0     0  0.262869  0.106507  0.006767  0.007038   \n",
       "2             0          0     1  0.316667  0.136352  0.006780  0.007179   \n",
       "3             0          3     0  0.279962  0.081136  0.007065  0.007421   \n",
       "4             0          1     0  0.314670  0.147348  0.007308  0.007315   \n",
       "...         ...        ...   ...       ...       ...       ...       ...   \n",
       "2793          6          1     0  0.329047  0.127826  0.316070  0.318500   \n",
       "2794          4          2     0  0.306651  0.138017  0.317420  0.322030   \n",
       "2795          5          0     0  0.351950  0.142881  0.318320  0.325380   \n",
       "2796          1          1     0  0.315244  0.118175  0.322610  0.322640   \n",
       "2797          0          2     2  0.243664  0.091839  0.314450  0.317830   \n",
       "\n",
       "           low  tv      Volume  \n",
       "0     0.006709  -1  29383228.0  \n",
       "1     0.006641   0  41415520.0  \n",
       "2     0.006745   1  31058927.0  \n",
       "3     0.007055   1  31100758.0  \n",
       "4     0.006738  -1  57350444.0  \n",
       "...        ...  ..         ...  \n",
       "2793  0.310220   1  19257761.8  \n",
       "2794  0.314180   1  22698952.2  \n",
       "2795  0.317000   1  22205970.7  \n",
       "2796  0.312610  -1  23157805.9  \n",
       "2797  0.312520   0  15291654.6  \n",
       "\n",
       "[2798 rows x 413 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0af292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_num = all_data_num.iloc[:,2:-1].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb531c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_num.drop(columns='tv')\n",
    "y = all_data_num['tv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a5918b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test  = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "y_train = pd.DataFrame(y_train, columns =['tv'])\n",
    "y_test  = pd.DataFrame(y_test, columns =['tv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41a7d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    853\n",
       " 1    849\n",
       " 0    256\n",
       "Name: tv, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[\"tv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "093a75d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='tv', ylabel='count'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y_train['tv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420dc3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1219\n",
       " 1    1217\n",
       " 0     362\n",
       "Name: tv, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X_train, y_train)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c470f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False  True  True  True\n",
      "  True False  True  True False  True  True False  True False False False\n",
      "  True False  True False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True]\n",
      "[  1   1  25   1   6  76 153 205 242 157  97 200 229  51  73 189 195 335\n",
      " 172 100  81 202 108 169 311 185 209 302 220 256 384 289 301 354 212 198\n",
      " 352 201 211 234 196 299 237 223 224 251 264 297 227 216 221 225 233 323\n",
      " 207 210 338 263 358 341 248 238 213 292 250 254 353 194 217 247 282 259\n",
      " 240 231 246 309 267 359 255 372 235 245 317 239 104 277 326 265 351 197\n",
      " 334 208 260 190 244 315 303 268 269 382 332 307 286 228 339 161 252 226\n",
      " 331 291 230 345 281 356 368 327 329 275 257 318 278 214 381 342 362 283\n",
      " 340 344 320 360 253 365 270 389 280 306 249 271 310 193 296 375 322 236\n",
      " 288 272 300 308 343 279 261 258 361 143 379 316 219 304 380 218 333 377\n",
      " 276 390 325 370 312 324 349 366 290 319 232 313 285 373 330 293 374 367\n",
      " 305 387 321 378 298 347 328 348 274 369 346 314 336 376 364 295 357 355\n",
      " 383 363 350   1   1   1   1 388   1   1   2   1   1  41   1   4  10  37\n",
      "   1  11   1  54 125   1  18  22  16  44  31   9  69   7  29  43  19 337\n",
      "  63  15 215  48  12 152  35  23  30  13 102  33  14   5  87  50  42  79\n",
      "  99  45  39  24 106  68  62 137 115 188  71  98 113  61   8  64 101  82\n",
      "  84   3  94  17  74  52  28  83  67 110 103 144  59  78  34  32  55  90\n",
      "  75 118  70 123  47 184  95  66 119 117 142  86  93 135 371  21  38 121\n",
      "  58  20 164  40 150 166  96  65  91  46 146 204  60  56  85  72 171 112\n",
      " 105 122 147 183 179 120 139 133 206 134  49 111 385 167 128 124 158 138\n",
      " 175 130 294 136 173  92  57 168 156 159 160 109 180 165 162 273  53 145\n",
      " 132 266  36 149 241 107 386  88 222  27 186 170 191  77 182  80 141 126\n",
      " 203 187 151 140 243 177 176 192 284 129 181 114  89 127 262 154 178 163\n",
      " 287 148  26 116 155 199 174 131   1   1   1   1   1]\n"
     ]
    }
   ],
   "source": [
    "#checking features with high importancy\n",
    "from sklearn.feature_selection import RFE\n",
    "data_final_vars = all_data_num.columns.values.tolist()\n",
    "rfc = RandomForestClassifier()\n",
    "rfe = RFE(rfc, n_features_to_select=20)\n",
    "rfe = rfe.fit(X_sm, y_sm.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "247f259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping features selected by RFE\n",
    "boolencolm = rfe.support_\n",
    "X_sm = pd.DataFrame(X_sm).loc[:, boolencolm]\n",
    "X_test = pd.DataFrame(X_test).loc[:, boolencolm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ba2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>replies_count_t</th>\n",
       "      <th>retweets_count_t</th>\n",
       "      <th>likes_count_t</th>\n",
       "      <th>subj_t</th>\n",
       "      <th>polar_t</th>\n",
       "      <th>replies_count_l</th>\n",
       "      <th>retweets_count_l</th>\n",
       "      <th>likes_count_l</th>\n",
       "      <th>dogecoin_l</th>\n",
       "      <th>elonmusk_l</th>\n",
       "      <th>buy_l</th>\n",
       "      <th>btc_l</th>\n",
       "      <th>eth_l</th>\n",
       "      <th>bitcoin_l</th>\n",
       "      <th>coin_l</th>\n",
       "      <th>subj_l</th>\n",
       "      <th>polar_l</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>950.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>6316.0</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>61.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.267342</td>\n",
       "      <td>0.117813</td>\n",
       "      <td>0.056686</td>\n",
       "      <td>0.056944</td>\n",
       "      <td>0.055306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351542</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.054068</td>\n",
       "      <td>0.054254</td>\n",
       "      <td>0.054017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.361863</td>\n",
       "      <td>0.050261</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>0.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.129520</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>0.008632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.301687</td>\n",
       "      <td>-0.065675</td>\n",
       "      <td>128.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0.353652</td>\n",
       "      <td>0.105273</td>\n",
       "      <td>0.053330</td>\n",
       "      <td>0.053914</td>\n",
       "      <td>0.052975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   replies_count_t  retweets_count_t  likes_count_t    subj_t   polar_t  \\\n",
       "0            950.0             939.0         6316.0  0.183333  0.100000   \n",
       "1             21.0             111.0         1036.0  0.225000  0.175000   \n",
       "2             12.0              64.0          220.0  0.000000  0.000000   \n",
       "3              0.0               0.0            0.0  0.000000  0.000000   \n",
       "4            162.0             338.0         1633.0  0.301687 -0.065675   \n",
       "\n",
       "   replies_count_l  retweets_count_l  likes_count_l  dogecoin_l  elonmusk_l  \\\n",
       "0             61.0             402.0         1153.0          62          16   \n",
       "1            129.0             428.0         1238.0          33          11   \n",
       "2             20.0              64.0          204.0          20           3   \n",
       "3             42.0             124.0          270.0          30           3   \n",
       "4            128.0             274.0          986.0          37           7   \n",
       "\n",
       "   buy_l  btc_l  eth_l  bitcoin_l  coin_l    subj_l   polar_l      open  \\\n",
       "0     14     11     10          8       5  0.267342  0.117813  0.056686   \n",
       "1      6     13     12          4       4  0.351542  0.190650  0.054068   \n",
       "2      1      0      0          0       0  0.361863  0.050261  0.009300   \n",
       "3      5     11      6          9       5  0.342627  0.129520  0.008849   \n",
       "4     14     14     17         11       4  0.353652  0.105273  0.053330   \n",
       "\n",
       "       high       low  \n",
       "0  0.056944  0.055306  \n",
       "1  0.054254  0.054017  \n",
       "2  0.009570  0.009278  \n",
       "3  0.009410  0.008632  \n",
       "4  0.053914  0.052975  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef01727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nb = CategoricalNB()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "nb.fit(X_sm, y_sm['tv'])\n",
    "rfc.fit(X_sm, y_sm['tv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e0553df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res_pred_rf = rfc.predict(X_sm)\n",
    "y_test_pred_rf      = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e308b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance_class(y_train, y_pred_train, y_test, y_pred_test):\n",
    "\n",
    "    from sklearn.metrics import cohen_kappa_score, classification_report \n",
    "\n",
    "\n",
    "    print(\"Results obtained for the TRAIN SET\")\n",
    "    print(\"==================================\")\n",
    "    print(\"The Cohen's Kappa is: {:.2f}\".format(cohen_kappa_score(y_train, y_pred_train)))\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    print(\"==================================\")\n",
    "    print(\"Results obtained for the TEST SET\")\n",
    "    print(\"The Cohen's Kappa is: {:.2f}\".format(cohen_kappa_score(y_test, y_pred_test)))\n",
    "    print(classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a4a258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results obtained for the TRAIN SET\n",
      "==================================\n",
      "The Cohen's Kappa is: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       853\n",
      "           0       1.00      1.00      1.00       853\n",
      "           1       1.00      1.00      1.00       853\n",
      "\n",
      "    accuracy                           1.00      2559\n",
      "   macro avg       1.00      1.00      1.00      2559\n",
      "weighted avg       1.00      1.00      1.00      2559\n",
      "\n",
      "==================================\n",
      "Results obtained for the TEST SET\n",
      "The Cohen's Kappa is: 0.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      0.47      0.48       366\n",
      "           0       0.20      0.29      0.23       106\n",
      "           1       0.47      0.42      0.44       368\n",
      "\n",
      "    accuracy                           0.43       840\n",
      "   macro avg       0.38      0.39      0.39       840\n",
      "weighted avg       0.44      0.43      0.43       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_performance_class(y_sm, y_train_res_pred_rf, y_test, y_test_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab35fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100,500, 1000],\n",
    "    'min_samples_split': [2, 4 , 6],\n",
    "    'min_samples_leaf' : [1, 2 , 3],\n",
    "    'max_features': ['sqrt']\n",
    "    ##'max_samples' : ['None', 0.5],\n",
    "    ##'max_depth':[3,5,10],\n",
    "    ## 'bootstrap':[True,False] \n",
    "    }\n",
    "clf = RandomForestClassifier(random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57af2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, param_grid, cv=5,return_train_score=True,n_jobs=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b230d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 500, 1000]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 500, 1000]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 4, 6],\n",
       "                         'n_estimators': [50, 100, 500, 1000]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_sm, y_sm.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb7217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaeb3844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.265384</td>\n",
       "      <td>0.085559</td>\n",
       "      <td>0.047126</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.550781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566237</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.985762</td>\n",
       "      <td>0.157731</td>\n",
       "      <td>0.057089</td>\n",
       "      <td>0.006891</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581086</td>\n",
       "      <td>0.020391</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.126612</td>\n",
       "      <td>0.205184</td>\n",
       "      <td>0.309728</td>\n",
       "      <td>0.102502</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.566406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585782</td>\n",
       "      <td>0.024813</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822603</td>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563498</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.635616</td>\n",
       "      <td>0.042431</td>\n",
       "      <td>0.063027</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.541016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570537</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.513081</td>\n",
       "      <td>0.698308</td>\n",
       "      <td>0.522504</td>\n",
       "      <td>0.279737</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 1...</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586174</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.541470</td>\n",
       "      <td>0.560018</td>\n",
       "      <td>0.027211</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.997559</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.120772</td>\n",
       "      <td>0.473560</td>\n",
       "      <td>0.084845</td>\n",
       "      <td>0.051822</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.564453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567017</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.371441</td>\n",
       "      <td>0.101787</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.537109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568973</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.940499</td>\n",
       "      <td>0.070596</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567025</td>\n",
       "      <td>0.022880</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.998046</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.997559</td>\n",
       "      <td>0.998437</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.626342</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.053819</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.564453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567017</td>\n",
       "      <td>0.017482</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.999316</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.586582</td>\n",
       "      <td>1.307075</td>\n",
       "      <td>0.216390</td>\n",
       "      <td>0.049748</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_features': 'sqrt', 'min_samples_leaf': 2...</td>\n",
       "      <td>0.537109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568973</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.265384      0.085559         0.047126        0.006619   \n",
       "1        1.985762      0.157731         0.057089        0.006891   \n",
       "2        9.126612      0.205184         0.309728        0.102502   \n",
       "3        0.822603      0.018539         0.029312        0.004440   \n",
       "4        1.635616      0.042431         0.063027        0.006854   \n",
       "5       11.513081      0.698308         0.522504        0.279737   \n",
       "6        1.541470      0.560018         0.027211        0.003608   \n",
       "7        2.120772      0.473560         0.084845        0.051822   \n",
       "8        8.371441      0.101787         0.268571        0.012377   \n",
       "9        0.940499      0.070596         0.028243        0.003875   \n",
       "10       1.626342      0.022791         0.053819        0.005812   \n",
       "11       7.586582      1.307075         0.216390        0.049748   \n",
       "\n",
       "   param_max_features param_min_samples_leaf param_min_samples_split  \\\n",
       "0                sqrt                      1                       2   \n",
       "1                sqrt                      1                       2   \n",
       "2                sqrt                      1                       2   \n",
       "3                sqrt                      1                       4   \n",
       "4                sqrt                      1                       4   \n",
       "5                sqrt                      1                       4   \n",
       "6                sqrt                      2                       2   \n",
       "7                sqrt                      2                       2   \n",
       "8                sqrt                      2                       2   \n",
       "9                sqrt                      2                       4   \n",
       "10               sqrt                      2                       4   \n",
       "11               sqrt                      2                       4   \n",
       "\n",
       "   param_n_estimators                                             params  \\\n",
       "0                  50  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "1                 100  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "2                 500  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "3                  50  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "4                 100  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "5                 500  {'max_features': 'sqrt', 'min_samples_leaf': 1...   \n",
       "6                  50  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "7                 100  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "8                 500  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "9                  50  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "10                100  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "11                500  {'max_features': 'sqrt', 'min_samples_leaf': 2...   \n",
       "\n",
       "    split0_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.550781  ...         0.566237        0.018432               11   \n",
       "1            0.562500  ...         0.581086        0.020391                3   \n",
       "2            0.566406  ...         0.585782        0.024813                2   \n",
       "3            0.554688  ...         0.563498        0.021493               12   \n",
       "4            0.541016  ...         0.570537        0.027463                4   \n",
       "5            0.546875  ...         0.586174        0.028800                1   \n",
       "6            0.570312  ...         0.567025        0.022880                7   \n",
       "7            0.564453  ...         0.567017        0.017482                9   \n",
       "8            0.537109  ...         0.568973        0.023696                5   \n",
       "9            0.570312  ...         0.567025        0.022880                7   \n",
       "10           0.564453  ...         0.567017        0.017482                9   \n",
       "11           0.537109  ...         0.568973        0.023696                5   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             1.000000            1.000000            1.000000   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5             1.000000            1.000000            1.000000   \n",
       "6             0.998534            0.999023            0.998046   \n",
       "7             0.999511            0.999511            0.999023   \n",
       "8             1.000000            0.999511            0.999023   \n",
       "9             0.998534            0.999023            0.998046   \n",
       "10            0.999511            0.999511            0.999023   \n",
       "11            1.000000            0.999511            0.999023   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             1.000000            1.000000          1.000000         0.000000  \n",
       "1             1.000000            1.000000          1.000000         0.000000  \n",
       "2             1.000000            1.000000          1.000000         0.000000  \n",
       "3             1.000000            0.999512          0.999902         0.000195  \n",
       "4             1.000000            0.999512          0.999902         0.000195  \n",
       "5             1.000000            1.000000          1.000000         0.000000  \n",
       "6             0.999023            0.997559          0.998437         0.000569  \n",
       "7             0.999511            0.999023          0.999316         0.000239  \n",
       "8             1.000000            1.000000          0.999707         0.000391  \n",
       "9             0.999023            0.997559          0.998437         0.000569  \n",
       "10            0.999511            0.999023          0.999316         0.000239  \n",
       "11            1.000000            1.000000          0.999707         0.000391  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9067321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4320460491889063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(random_state=0, max_features='sqrt', \n",
    "                             min_samples_leaf=1, min_samples_split=4, n_estimators=500)\n",
    "cross_val_scores = cross_val_score(clf, X_train, y_train.values.ravel() , cv=10)\n",
    "print(np.mean(cross_val_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
